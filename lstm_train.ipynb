{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-train",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFuXtJT8tQ_w",
        "outputId": "bb210b7b-28ba-4f4e-e5d0-25d5cfb368b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFJPw7yHAl1H"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/ML_LSTM/dataset/ /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-kYWBOTmyZv"
      },
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZH0V6UsnEWB"
      },
      "source": [
        "# CSVファイルからデータをDataFrame型で取得する\n",
        "def get_df_data():\n",
        "    df_data = pd.read_csv('dataset/dataset_train.csv', index_col=0, parse_dates=True, skiprows = 1, encoding = 'utf8', header=None)\n",
        "    df_data.columns = [\n",
        "        'sensor1',\n",
        "        'sensor2',\n",
        "        'sensor3',\n",
        "        'sensor4',\n",
        "        'feed1',\n",
        "        'feed2',\n",
        "        'feed3',\n",
        "        'feed4',\n",
        "    ]\n",
        "\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFCOIKXRnIC3"
      },
      "source": [
        "\n",
        "# モデルに読み込ませるデータを生成する\n",
        "def generate_data(data, length_per_unit, dimension):\n",
        "    # DataFrame→array変換\n",
        "    data_array = data.values\n",
        "    # 時系列データを入れる箱\n",
        "    sequences = []\n",
        "    # 正解データを入れる箱\n",
        "    target = []\n",
        "    # 正解データの日付を入れる箱\n",
        "    target_date = []\n",
        "\n",
        "    # 一グループごとに時系列データと正解データをセットしていく\n",
        "    for i in range(0, data_array.shape[0] - length_per_unit):\n",
        "        sequences.append(data_array[i:i + length_per_unit])\n",
        "        target.append(data_array[i + length_per_unit])\n",
        "        target_date.append(data[i + length_per_unit: i + length_per_unit + 1].index.strftime('%Y/%m/%d'))\n",
        "\n",
        "    # 時系列データを成形\n",
        "    X = np.array(sequences).reshape(len(sequences), length_per_unit, dimension)\n",
        "    # 正解データを成形\n",
        "    Y = np.array(target).reshape(len(sequences), dimension)\n",
        "    # 正解データの日付データを成形\n",
        "    Y_date = np.array(target_date).reshape(len(sequences), 1)\n",
        "\n",
        "    return (X, Y, Y_date)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWzCH25-nJ6Y"
      },
      "source": [
        "\n",
        "# モデルリストを取得する\n",
        "def get_model_list(input_shape):\n",
        "    # 実行するモデル一覧\n",
        "    model_list = [\n",
        "        ['LSTM_1', Sequential([\n",
        "            LSTM(100, input_shape=input_shape), \n",
        "            Dense(4), \n",
        "            Activation(\"linear\")])], \n",
        "        ['LSTM_2', Sequential([\n",
        "            LSTM(300, input_shape=input_shape), \n",
        "            Dense(4), \n",
        "            Activation(\"linear\")])], \n",
        "    ]\n",
        "\n",
        "    return model_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyh7Xvb_nOX8"
      },
      "source": [
        "# 扱う特徴量\n",
        "FEATURE_VALUE = ['feed1','feed2','feed3','feed4']\n",
        "# 次元数\n",
        "DIMENSION = len(FEATURE_VALUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaChvijnThX",
        "outputId": "ff403168-f0f5-4b42-df0b-4f421c19bf13"
      },
      "source": [
        "# データを取得\n",
        "df_data = get_df_data()\n",
        "print(df_data)\n",
        "# 学習用データを取得(日付順にソート)\n",
        "df_data_train = df_data.loc['1993-01-01':'2020-12-10', FEATURE_VALUE]\n",
        "df_data_train = df_data_train.sort_index()\n",
        "df_data_train = df_data_train.dropna() # 欠損値のある行を取り除く\n",
        "print(df_data_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            sensor1  sensor2  sensor3  sensor4  feed1  feed2  feed3  feed4\n",
            "0                                                                         \n",
            "1993-01-01        0        0        0        0     10      0      0      0\n",
            "1993-01-02        0        0        0        0     10      0      0      0\n",
            "1993-01-03        0        0        0        0     10      0      0      0\n",
            "1993-01-04       10        0        0        0      8      2      0      0\n",
            "1993-01-05        8        2        0        0      7      3      0      0\n",
            "...             ...      ...      ...      ...    ...    ...    ...    ...\n",
            "2020-12-06        1        1        7        1      0      0      2      8\n",
            "2020-12-07        1        1        5        3      0      0      4      6\n",
            "2020-12-08        1        1        1        7      0      0      0     10\n",
            "2020-12-09        1        1        1        7      0      0      0     10\n",
            "2020-12-10        1        1        1        7      0      0      0     10\n",
            "\n",
            "[10206 rows x 8 columns]\n",
            "            feed1  feed2  feed3  feed4\n",
            "0                                     \n",
            "1993-01-01     10      0      0      0\n",
            "1993-01-02     10      0      0      0\n",
            "1993-01-03     10      0      0      0\n",
            "1993-01-04      8      2      0      0\n",
            "1993-01-05      7      3      0      0\n",
            "...           ...    ...    ...    ...\n",
            "2020-12-06      0      0      2      8\n",
            "2020-12-07      0      0      4      6\n",
            "2020-12-08      0      0      0     10\n",
            "2020-12-09      0      0      0     10\n",
            "2020-12-10      0      0      0     10\n",
            "\n",
            "[10206 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7WmqHUHnXgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b45260-f178-4458-b451-47117cc47cf7"
      },
      "source": [
        "# 一つの時系列データの長さ\n",
        "LENGTH_PER_UNIT = 10\n",
        "X_train, Y_train, Y_train_date = generate_data(df_data_train, LENGTH_PER_UNIT, DIMENSION)\n",
        "# 正規化\n",
        "X_train = X_train / np.nanmax(np.abs(X_train))\n",
        "print(X_train)\n",
        "\n",
        "# 入力の形状\n",
        "input_shape=(LENGTH_PER_UNIT, DIMENSION)\n",
        "\n",
        "model_list = get_model_list(input_shape)\n",
        "\n",
        "# 最適化手法の設定\n",
        "opt = optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.  0.  0.  0. ]\n",
            "  [1.  0.  0.  0. ]\n",
            "  [1.  0.  0.  0. ]\n",
            "  ...\n",
            "  [0.2 0.3 0.5 0. ]\n",
            "  [0.1 0.4 0.5 0. ]\n",
            "  [0.1 0.3 0.6 0. ]]\n",
            "\n",
            " [[1.  0.  0.  0. ]\n",
            "  [1.  0.  0.  0. ]\n",
            "  [0.8 0.2 0.  0. ]\n",
            "  ...\n",
            "  [0.1 0.4 0.5 0. ]\n",
            "  [0.1 0.3 0.6 0. ]\n",
            "  [0.1 0.2 0.7 0. ]]\n",
            "\n",
            " [[1.  0.  0.  0. ]\n",
            "  [0.8 0.2 0.  0. ]\n",
            "  [0.7 0.3 0.  0. ]\n",
            "  ...\n",
            "  [0.1 0.3 0.6 0. ]\n",
            "  [0.1 0.2 0.7 0. ]\n",
            "  [0.1 0.1 0.8 0. ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.3 0.5 0.2 0. ]\n",
            "  [0.2 0.4 0.4 0. ]\n",
            "  [0.  0.3 0.4 0.1]\n",
            "  ...\n",
            "  [0.  0.  0.4 0.6]\n",
            "  [0.  0.  0.2 0.8]\n",
            "  [0.  0.  0.4 0.6]]\n",
            "\n",
            " [[0.2 0.4 0.4 0. ]\n",
            "  [0.  0.3 0.4 0.1]\n",
            "  [0.  0.4 0.5 0.1]\n",
            "  ...\n",
            "  [0.  0.  0.2 0.8]\n",
            "  [0.  0.  0.4 0.6]\n",
            "  [0.  0.  0.  1. ]]\n",
            "\n",
            " [[0.  0.3 0.4 0.1]\n",
            "  [0.  0.4 0.5 0.1]\n",
            "  [0.  0.4 0.5 0.1]\n",
            "  ...\n",
            "  [0.  0.  0.4 0.6]\n",
            "  [0.  0.  0.  1. ]\n",
            "  [0.  0.  0.  1. ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "pMsKIdQ2nfG0",
        "outputId": "b83df43e-c5fa-4697-e5fa-977863742ca4"
      },
      "source": [
        "# 全てのモデルについて実行する\n",
        "for save_path, model in model_list:\n",
        "    # 結果格納用のフォルダ作成\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "    # モデルの要約を出力\n",
        "    model.summary()\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer = opt,        # 最適化手法\n",
        "            loss = 'mean_squared_error',           # 損失関数\n",
        "            metrics = ['accuracy']) # 評価関数\n",
        "\n",
        "    # 途中で保存するモデル基準設定\n",
        "    fpath = save_path + '/weights.{epoch:03d}-{loss:.2f}-{accuracy:.2f}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5'\n",
        "    model_ckp = ModelCheckpoint(filepath = fpath, monitor='loss', verbose=1, save_best_only=True, mode='auto', period=5)\n",
        "\n",
        "    # 学習\n",
        "    history = model.fit(X_train, Y_train, \n",
        "                        epochs=50, \n",
        "                        batch_size=10, \n",
        "                        validation_split=0.1, \n",
        "                        callbacks=[model_ckp])\n",
        "    \n",
        "    #Accuracyの推移\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy : ' + save_path)\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(save_path + '/accuracy.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Lossの推移\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss : ' + save_path)\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(save_path + '/loss.png')\n",
        "\n",
        "    # モデルと学習結果を保存する\n",
        "    model_json_str = model.to_json()\n",
        "    open(save_path + '/Keras_rnn.json', 'w').write(model_json_str)\n",
        "    model.save_weights(save_path + '/Keras_rnn_weights.h5')\n",
        "\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100)               42000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 404       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 42,404\n",
            "Trainable params: 42,404\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f87e5b2af5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                         callbacks=[model_ckp])\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#Accuracyの推移\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tip0f9JOtuR0"
      },
      "source": [
        "!cp -r /content/LSTM_1/ /content/drive/MyDrive/ML_LSTM/\n",
        "!cp -r /content/LSTM_2/ /content/drive/MyDrive/ML_LSTM/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}